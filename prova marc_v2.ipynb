{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🧠 Análisis de la Readmisión a la UCI en Pacientes con Hemorragia Intracerebral (MIMIC-IV)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 🔧 Configuración Inicial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello, World!\n"
          ]
        }
      ],
      "source": [
        "from google.cloud import bigquery\n",
        "from google.oauth2 import service_account\n",
        "\n",
        "# Path to your service account key file\n",
        "SERVICE_ACCOUNT_FILE = \"mimic-sergi.json\"\n",
        "PROJECT_ID = \"ogi-uci-i61\"\n",
        "\n",
        "# Create credentials and client\n",
        "credentials = service_account.Credentials.from_service_account_file(\n",
        "    SERVICE_ACCOUNT_FILE)\n",
        "\n",
        "client = bigquery.Client(credentials=credentials, project=PROJECT_ID)\n",
        "\n",
        "# Example query\n",
        "query = \"SELECT 'Hello, World!' AS greeting\"\n",
        "query_job = client.query(query)\n",
        "\n",
        "# Fetch results\n",
        "results = query_job.result()\n",
        "\n",
        "for row in results:\n",
        "    print(row.greeting)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 📦 Extracción de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SQL query para extraer datos de pacientes con HIC (Hemorragia Intracerebral) en la UCI\n",
        "query = \"\"\"\n",
        "-- Updated SQL query for ICH patients in ICU with corrected joins to derived lab tables\n",
        "WITH ich_admissions AS (\n",
        "  SELECT DISTINCT hadm_id\n",
        "  FROM `ogi-uci-i61.mimiciv_hosp.diagnoses_icd` i\n",
        "  JOIN `ogi-uci-i61.mimiciv_hosp.d_icd_diagnoses` d\n",
        "    ON i.icd_code = d.icd_code AND i.icd_version = d.icd_version\n",
        "  WHERE LOWER(d.long_title) LIKE '%intracerebral hemorrhage%'\n",
        "),\n",
        "\n",
        "chartevents_avg AS (\n",
        "  SELECT\n",
        "    c.stay_id,\n",
        "    AVG(CASE WHEN itemid = 220045 AND valuenum > 0 THEN valuenum END) AS heart_rate_avg,\n",
        "    AVG(CASE WHEN itemid = 220052 AND valuenum BETWEEN 30 AND 200 THEN valuenum END) AS mbp_avg,\n",
        "    AVG(CASE WHEN itemid = 220210 AND valuenum BETWEEN 5 AND 60 THEN valuenum END) AS resp_rate_avg,\n",
        "    AVG(CASE WHEN itemid = 220277 AND valuenum BETWEEN 70 AND 100 THEN valuenum END) AS spo2_avg,\n",
        "    AVG(CASE WHEN itemid = 223762 AND valuenum BETWEEN 33 AND 43 THEN valuenum END) AS temperature_avg\n",
        "  FROM `ogi-uci-i61.mimiciv_icu.chartevents` c\n",
        "  JOIN `ogi-uci-i61.mimiciv_icu.icustays` i ON c.stay_id = i.stay_id\n",
        "  WHERE\n",
        "    c.itemid IN (220045, 220052, 220210, 220277, 223762)\n",
        "    AND c.valuenum IS NOT NULL\n",
        "    AND c.charttime BETWEEN i.intime AND i.outtime\n",
        "  GROUP BY c.stay_id\n",
        "),\n",
        "\n",
        "cbc_labs AS (\n",
        "  SELECT subject_id, hadm_id,\n",
        "    MIN(wbc) AS wbc_min,\n",
        "    MIN(hemoglobin) AS hgb_min,\n",
        "    MIN(hematocrit) AS hct_min\n",
        "  FROM `ogi-uci-i61.mimiciv_derived.complete_blood_count`\n",
        "  GROUP BY subject_id, hadm_id\n",
        "),\n",
        "\n",
        "chem_labs AS (\n",
        "  SELECT subject_id, hadm_id,\n",
        "    MIN(sodium) AS sodium_min,\n",
        "    MIN(creatinine) AS creatinine_min,\n",
        "    MIN(glucose) AS glucose_min\n",
        "  FROM `ogi-uci-i61.mimiciv_derived.chemistry`\n",
        "  GROUP BY subject_id, hadm_id\n",
        "),\n",
        "\n",
        "coag_labs AS (\n",
        "  SELECT subject_id, hadm_id,\n",
        "    MIN(inr) AS inr_min,\n",
        "    MIN(pt) AS pt_min\n",
        "  FROM `ogi-uci-i61.mimiciv_derived.coagulation`\n",
        "  GROUP BY subject_id, hadm_id\n",
        "),\n",
        "\n",
        "readmission_within_30_days AS (\n",
        "  SELECT\n",
        "    a1.subject_id,\n",
        "    a1.stay_id,\n",
        "    MIN(a2.stay_id) AS readmitted_stay\n",
        "  FROM `ogi-uci-i61.mimiciv_icu.icustays` a1\n",
        "  JOIN `ogi-uci-i61.mimiciv_icu.icustays` a2\n",
        "    ON a1.subject_id = a2.subject_id\n",
        "    AND a2.intime > a1.outtime\n",
        "    AND DATETIME_DIFF(a2.intime, a1.outtime, DAY) <= 30\n",
        "  GROUP BY a1.subject_id, a1.stay_id\n",
        ")\n",
        "\n",
        "SELECT\n",
        "  a.subject_id,\n",
        "  a.hadm_id,\n",
        "  a.stay_id,\n",
        "  p.gender,\n",
        "  p.anchor_age AS age,\n",
        "  a.intime,\n",
        "  a.outtime,\n",
        "  a.first_careunit,\n",
        "  TIMESTAMP_DIFF(a.outtime, a.intime, HOUR) AS icu_los_hours,\n",
        "  TIMESTAMP_DIFF(adm.dischtime, adm.admittime, HOUR) AS hosp_los_hours,\n",
        "  adm.discharge_location,\n",
        "  adm.hospital_expire_flag,\n",
        "\n",
        "  STRING_AGG(CASE WHEN LOWER(d.long_title) LIKE '%intracerebral hemorrhage%' THEN i.icd_code END, '; ') AS ich_icd_codes,\n",
        "  STRING_AGG(CASE WHEN LOWER(d.long_title) LIKE '%intracerebral hemorrhage%' THEN CONCAT(i.icd_code, ': ', d.long_title) ELSE i.icd_code END, '; ') AS all_diagnoses,\n",
        "\n",
        "  s.gcs_verbal,\n",
        "  s.gcs_motor,\n",
        "  s.gcs_eyes,\n",
        "\n",
        "  vitals.heart_rate,\n",
        "  vitals.mbp,\n",
        "  vitals.resp_rate,\n",
        "  vitals.temperature,\n",
        "  vitals.spo2,\n",
        "  ce.heart_rate_avg,\n",
        "  ce.mbp_avg,\n",
        "  ce.resp_rate_avg,\n",
        "  ce.spo2_avg,\n",
        "  ce.temperature_avg,\n",
        "\n",
        "  -- Derived Scores and Labs\n",
        "  charlson.charlson_comorbidity_index,\n",
        "  apsi.apsiii,\n",
        "  code_status.dnr,\n",
        "  code_status.dni,\n",
        "  code_status.fullcode,\n",
        "  code_status.cmo,\n",
        "  cbc.wbc_min, cbc.hgb_min, cbc.hct_min,\n",
        "  chem.sodium_min, chem.creatinine_min, chem.glucose_min,\n",
        "  coag.inr_min, coag.pt_min,\n",
        "\n",
        "  CASE WHEN hyper.hadm_id IS NOT NULL THEN 1 ELSE 0 END AS has_hypertension,\n",
        "  CASE WHEN hydro.hadm_id IS NOT NULL THEN 1 ELSE 0 END AS has_hydrocephalus,\n",
        "  CASE WHEN cad.hadm_id IS NOT NULL THEN 1 ELSE 0 END AS has_cad,\n",
        "  CASE WHEN anticoag.subject_id IS NOT NULL THEN 1 ELSE 0 END AS has_anticoagulation,\n",
        "  CASE WHEN neuroproc.hadm_id IS NOT NULL THEN 1 ELSE 0 END AS had_neurosurgery,\n",
        "  CASE WHEN addmeds.subject_id IS NOT NULL THEN 1 ELSE 0 END AS on_statins_or_antiplatelets,\n",
        "\n",
        "  readmit.readmitted_stay\n",
        "\n",
        "FROM `ogi-uci-i61.mimiciv_icu.icustays` a\n",
        "JOIN `ogi-uci-i61.mimiciv_hosp.patients` p ON a.subject_id = p.subject_id\n",
        "JOIN `ogi-uci-i61.mimiciv_hosp.admissions` adm ON a.hadm_id = adm.hadm_id\n",
        "JOIN ich_admissions ich ON a.hadm_id = ich.hadm_id\n",
        "LEFT JOIN `ogi-uci-i61.mimiciv_hosp.diagnoses_icd` i ON a.hadm_id = i.hadm_id\n",
        "LEFT JOIN `ogi-uci-i61.mimiciv_hosp.d_icd_diagnoses` d ON i.icd_code = d.icd_code AND i.icd_version = d.icd_version\n",
        "\n",
        "LEFT JOIN (\n",
        "  SELECT stay_id, gcs_verbal, gcs_motor, gcs_eyes,\n",
        "         ROW_NUMBER() OVER (PARTITION BY stay_id ORDER BY charttime) AS rn\n",
        "  FROM `ogi-uci-i61.mimiciv_derived.gcs`\n",
        ") s ON a.stay_id = s.stay_id AND s.rn = 1\n",
        "\n",
        "LEFT JOIN (\n",
        "  SELECT stay_id, heart_rate, mbp, resp_rate, temperature, spo2,\n",
        "         ROW_NUMBER() OVER (PARTITION BY stay_id ORDER BY charttime) AS rn\n",
        "  FROM `ogi-uci-i61.mimiciv_derived.vitalsign`\n",
        ") vitals ON a.stay_id = vitals.stay_id AND vitals.rn = 1\n",
        "\n",
        "LEFT JOIN chartevents_avg ce ON a.stay_id = ce.stay_id\n",
        "LEFT JOIN readmission_within_30_days readmit ON a.subject_id = readmit.subject_id AND a.stay_id = readmit.stay_id\n",
        "\n",
        "-- Derived Scores and Corrected Lab Joins\n",
        "LEFT JOIN `ogi-uci-i61.mimiciv_derived.charlson` charlson ON a.hadm_id = charlson.hadm_id\n",
        "LEFT JOIN `ogi-uci-i61.mimiciv_derived.apsiii` apsi ON a.stay_id = apsi.stay_id\n",
        "LEFT JOIN `ogi-uci-i61.mimiciv_derived.code_status` code_status ON a.stay_id = code_status.stay_id\n",
        "LEFT JOIN cbc_labs cbc ON a.subject_id = cbc.subject_id AND a.hadm_id = cbc.hadm_id\n",
        "LEFT JOIN chem_labs chem ON a.subject_id = chem.subject_id AND a.hadm_id = chem.hadm_id\n",
        "LEFT JOIN coag_labs coag ON a.subject_id = coag.subject_id AND a.hadm_id = coag.hadm_id\n",
        "\n",
        "LEFT JOIN (\n",
        "  SELECT DISTINCT hadm_id\n",
        "  FROM `ogi-uci-i61.mimiciv_hosp.diagnoses_icd`\n",
        "  WHERE icd_code LIKE '401%' OR icd_code LIKE 'I10%'\n",
        ") hyper ON a.hadm_id = hyper.hadm_id\n",
        "\n",
        "LEFT JOIN (\n",
        "  SELECT DISTINCT hadm_id\n",
        "  FROM `ogi-uci-i61.mimiciv_hosp.diagnoses_icd`\n",
        "  WHERE icd_code LIKE '331.3' OR icd_code LIKE 'G91%'\n",
        ") hydro ON a.hadm_id = hydro.hadm_id\n",
        "\n",
        "LEFT JOIN (\n",
        "  SELECT DISTINCT hadm_id\n",
        "  FROM `ogi-uci-i61.mimiciv_hosp.diagnoses_icd`\n",
        "  WHERE icd_code LIKE '414%' OR icd_code LIKE 'I25%'\n",
        ") cad ON a.hadm_id = cad.hadm_id\n",
        "\n",
        "LEFT JOIN (\n",
        "  SELECT DISTINCT subject_id\n",
        "  FROM `ogi-uci-i61.mimiciv_hosp.prescriptions`\n",
        "  WHERE REGEXP_CONTAINS(LOWER(drug), r'(warfarin|heparin|apixaban|rivaroxaban|dabigatran)')\n",
        "    AND drug_type = 'MAIN'\n",
        ") anticoag ON a.subject_id = anticoag.subject_id\n",
        "\n",
        "LEFT JOIN (\n",
        "  SELECT DISTINCT subject_id\n",
        "  FROM `ogi-uci-i61.mimiciv_hosp.prescriptions`\n",
        "  WHERE REGEXP_CONTAINS(LOWER(drug), r'(aspirin|clopidogrel|atorvastatin|rosuvastatin)')\n",
        "    AND drug_type = 'MAIN'\n",
        ") addmeds ON a.subject_id = addmeds.subject_id\n",
        "\n",
        "LEFT JOIN (\n",
        "  SELECT DISTINCT hadm_id\n",
        "  FROM `ogi-uci-i61.mimiciv_hosp.procedures_icd`\n",
        "  WHERE icd_code LIKE '01%' OR icd_code LIKE '02%'\n",
        ") neuroproc ON a.hadm_id = neuroproc.hadm_id\n",
        "\n",
        "GROUP BY\n",
        "  a.subject_id, a.hadm_id, a.stay_id, a.intime, a.outtime, a.first_careunit,\n",
        "  p.gender, p.anchor_age, adm.admittime, adm.dischtime, adm.discharge_location, adm.hospital_expire_flag,\n",
        "  s.gcs_verbal, s.gcs_motor, s.gcs_eyes,\n",
        "  vitals.heart_rate, vitals.mbp, vitals.resp_rate, vitals.temperature, vitals.spo2,\n",
        "  ce.heart_rate_avg, ce.mbp_avg, ce.resp_rate_avg, ce.spo2_avg, ce.temperature_avg,\n",
        "  charlson.charlson_comorbidity_index,\n",
        "  apsi.apsiii,\n",
        "  code_status.dnr, code_status.dni, code_status.fullcode, code_status.cmo,\n",
        "  cbc.wbc_min, cbc.hgb_min, cbc.hct_min,\n",
        "  chem.sodium_min, chem.creatinine_min, chem.glucose_min,\n",
        "  coag.inr_min, coag.pt_min,\n",
        "  hyper.hadm_id, hydro.hadm_id, cad.hadm_id,\n",
        "  anticoag.subject_id, addmeds.subject_id, neuroproc.hadm_id,\n",
        "  readmit.readmitted_stay\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Ejecutar la consulta\n",
        "df = client.query(query).to_dataframe()\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 🧽 Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create target variable (readmitted)\n",
        "print(\"\\nNulls in readmitted_stay before fillna:\", df['readmitted_stay'].isnull().sum())\n",
        "\n",
        "# Check how many unique stay IDs there are\n",
        "unique_stay_ids = df['stay_id'].nunique()\n",
        "print(f\"\\nNumber of unique stay IDs: {unique_stay_ids}\")\n",
        "\n",
        "# Check for duplicate stay IDs (if any)\n",
        "duplicate_stay_ids = df['stay_id'].duplicated().sum()\n",
        "print(f\"Number of duplicate stay IDs: {duplicate_stay_ids}\")\n",
        "\n",
        "# Check how many unique hadm IDs there are\n",
        "unique_hadm_ids = df['hadm_id'].nunique()\n",
        "print(f\"\\nNumber of unique hadm IDs: {unique_hadm_ids}\")\n",
        "\n",
        "# Check for duplicate stay IDs (if any)\n",
        "duplicate_hadm_ids = df['hadm_id'].duplicated().sum()\n",
        "print(f\"Number of duplicate hadm IDs: {duplicate_hadm_ids}\")\n",
        "\n",
        "\n",
        "# Define readmitted (1 if readmitted_stay is not null, 0 otherwise)\n",
        "df['readmitted'] = df['readmitted_stay'].notnull().astype(int)  # Or (df['readmitted_stay'] > 0).astype(int)\n",
        "print(\"Class distribution in readmitted:\", df['readmitted'].value_counts())\n",
        "\n",
        "# Explicitly convert icu_los_hours to numerical type\n",
        "df['icu_los_hours'] = pd.to_numeric(df['icu_los_hours'])\n",
        "\n",
        "# Convert to categorical \n",
        "df['gcs_verbal'] = df['gcs_verbal'].astype('category')\n",
        "df['gcs_motor'] = df['gcs_motor'].astype('category')\n",
        "df['gcs_eyes'] = df['gcs_eyes'].astype('category')\n",
        "df['gender'] = df['gender'].astype('category')\n",
        "\n",
        "# Split semicolon-separated codes into lists for all diagnoses\n",
        "df['all_diagnoses_list'] = df['all_diagnoses'].str.split(';')\n",
        "\n",
        "# Get all ICD codes and their frequencies\n",
        "all_codes = df['all_diagnoses_list'].explode().str.strip()\n",
        "# Extract just the ICD code (before the colon, if present)\n",
        "all_codes = all_codes.str.split(':').str[0].str.strip()\n",
        "all_codes = all_codes[all_codes != '']  # Exclude empty strings\n",
        "\n",
        "# Filter out ICH-related codes\n",
        "# Assuming ICH codes are those in ich_icd_codes or identified by the SQL condition\n",
        "ich_codes = df['ich_icd_codes'].str.split(';').explode().str.strip().unique()\n",
        "ich_codes = [code for code in ich_codes if code]  # Remove empty strings\n",
        "non_ich_codes = all_codes[~all_codes.isin(ich_codes)]\n",
        "\n",
        "# Get frequency of non-ICH codes\n",
        "non_ich_code_counts = non_ich_codes.value_counts()\n",
        "\n",
        "# Identify the 10 most frequent non-ICH codes\n",
        "top_10_non_ich_codes = non_ich_code_counts.head(20).index.tolist()\n",
        "print(f\"\\nTop 10 most frequent non-ICH ICD-10 codes: {top_10_non_ich_codes}\")\n",
        "print(\"Frequency of non-ICH codes:\")\n",
        "print(non_ich_code_counts.head(20))\n",
        "\n",
        "# One-hot encode the top 10 non-ICH codes\n",
        "for code in top_10_non_ich_codes:\n",
        "    df[f'non_ich_{code}'] = df['all_diagnoses'].str.contains(code, na=False).astype(int)\n",
        "\n",
        "# Drop temporary column\n",
        "df = df.drop(columns=['all_diagnoses_list'], errors='ignore')\n",
        "\n",
        "# Optionally, if you still want to one-hot encode ICH codes (as in your original code)\n",
        "df['ich_icd_codes_list'] = df['ich_icd_codes'].str.split(';')\n",
        "all_ich_codes = df['ich_icd_codes_list'].explode().str.strip()\n",
        "all_ich_codes = all_ich_codes[all_ich_codes != '']\n",
        "ich_code_counts = all_ich_codes.value_counts()\n",
        "top_7_ich_codes = ich_code_counts.head(7).index.tolist()\n",
        "print(f\"\\nTop 7 most frequent ICH ICD-10 codes: {top_7_ich_codes}\")\n",
        "print(\"Frequency of ICH codes:\")\n",
        "print(ich_code_counts)\n",
        "\n",
        "for code in top_7_ich_codes:\n",
        "    df[f'ich_{code}'] = df['ich_icd_codes'].str.contains(code, na=False).astype(int)\n",
        "\n",
        "# Drop temporary ICH column\n",
        "df = df.drop(columns=['ich_icd_codes_list'], errors='ignore')\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "subject_id                  Int64\n",
            "hadm_id                     Int64\n",
            "stay_id                     Int64\n",
            "gender                     object\n",
            "intime             datetime64[us]\n",
            "outtime            datetime64[us]\n",
            "icd_code                   object\n",
            "icd_version                 Int64\n",
            "long_title                 object\n",
            "gcs_verbal                float64\n",
            "gcs_motor                 float64\n",
            "gcs_eyes                  float64\n",
            "heart_rate                float64\n",
            "mbp                       float64\n",
            "resp_rate                 float64\n",
            "temperature                object\n",
            "spo2                      float64\n",
            "readmitted_stay             Int64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Primer hauríem de mirar quins tipus de dades conté cada columna\n",
        "print(df.dtypes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 📊 Modelado Predictivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nulls in readmitted_stay before fillna: 3222\n",
            "readmitted_stay summary: count              938.0\n",
            "mean     35030430.127932\n",
            "std       2878265.870109\n",
            "min           30024491.0\n",
            "25%           32506322.0\n",
            "50%           34949251.5\n",
            "75%          37500054.75\n",
            "max           39979862.0\n",
            "Name: readmitted_stay, dtype: Float64\n",
            "Class distribution in readmitted: readmitted\n",
            "0    3222\n",
            "1     938\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from decimal import Decimal\n",
        "\n",
        "# Calculate missing percentages\n",
        "missing_pct = (df.isnull().sum() / len(df) * 100).round(2)\n",
        "print(\"Missing percentages per column:\")\n",
        "print(missing_pct.sort_values(ascending=False))\n",
        "\n",
        "# Set missing data threshold\n",
        "missing_threshold = 60  # Exclude columns with >60% missing\n",
        "columns_to_exclude = missing_pct[missing_pct > missing_threshold].index\n",
        "print(f\"\\nColumns with >{missing_threshold}% missing: {list(columns_to_exclude)}\")\n",
        "\n",
        "# Exclude high-missingness columns, but keep readmitted_stay for target creation\n",
        "features_to_keep = [col for col in df.columns if col not in columns_to_exclude or col == 'readmitted_stay']\n",
        "df_clean = df.loc[:, features_to_keep]\n",
        "\n",
        "# Handle Decimal values and fill NaNs\n",
        "# Convert Decimal to float for numerical columns\n",
        "numerical_cols = df_clean.select_dtypes(include=['number', 'Int64', 'float64', 'int64']).columns\n",
        "for col in numerical_cols:\n",
        "    df_clean.loc[:, col] = df_clean[col].apply(lambda x: float(x) if isinstance(x, Decimal) else x)\n",
        "\n",
        "# Identify integer columns\n",
        "int_columns = df_clean.select_dtypes(include=['Int64', 'int64']).columns\n",
        "# Fill NaNs with rounded medians for integer columns\n",
        "for col in int_columns:\n",
        "    median_val = df_clean[col].median()\n",
        "    if not pd.isna(median_val):\n",
        "        df_clean.loc[:, col] = df_clean[col].fillna(int(median_val))\n",
        "\n",
        "# Fill NaNs for other numeric columns, excluding readmitted_stay and readmitted\n",
        "numeric_cols = df_clean.select_dtypes(include='number').columns.difference(['readmitted_stay', 'readmitted'])\n",
        "df_clean.loc[:, numeric_cols] = df_clean[numeric_cols].fillna(df_clean[numeric_cols].median())\n",
        "\n",
        "# Handle readmitted_stay separately\n",
        "df_clean.loc[:, 'readmitted_stay'] = df_clean['readmitted_stay'].fillna(0)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "feature_cols = df_clean.select_dtypes(include='number').columns[\n",
        "    ~df_clean.select_dtypes(include='number').columns.str.startswith(('non_ich', 'ich'))\n",
        "].difference(['readmitted_stay', 'readmitted', 'subject_id', 'hadm_id', 'stay_id', 'intime', 'outtime', 'has_hypertension', 'has_hydrocephalus', 'has_cad', 'has_anticoagulation', 'had_neurosurgery'])\n",
        "features_scaled = scaler.fit_transform(df_clean[feature_cols])\n",
        "df_clean.loc[:, feature_cols] = features_scaled\n",
        "\n",
        "# Remove columns that are not needed for the final dataset \n",
        "df_clean = df_clean.drop(columns=['intime', 'outtime', 'subject_id', 'hadm_id', 'stay_id', 'readmitted_stay', 'all_diagnoses','ich_icd_codes'], errors='ignore')\n",
        "\n",
        "df_clean\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from pycaret.classification import *\n",
        "\n",
        "# Prepare data for PyCaret\n",
        "ordinal_features = {\n",
        "    'gcs_verbal': [0.0, 1.0, 2.0, 3.0, 4.0, 5.0],\n",
        "    'gcs_motor':  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0],\n",
        "    'gcs_eyes':   [0.0, 1.0, 2.0, 3.0, 4.0]\n",
        "}\n",
        "feature_cols = df_clean.columns.difference(['readmitted'])\n",
        "X = df_clean[feature_cols]\n",
        "y = df_clean['readmitted']\n",
        "print(\"y value counts:\", y.value_counts())\n",
        "print(\"y unique values:\", y.unique())\n",
        "\n",
        "clf_setup = setup(\n",
        "    data=df_clean,\n",
        "    target='readmitted',\n",
        "    ordinal_features=ordinal_features,\n",
        "    normalize=False,\n",
        "    session_id=42,\n",
        "    fix_imbalance=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the initial round of model evaluation, most classifiers achieved high accuracy (around 77%) but extremely low recall and F1 scores. This indicated that the models were predominantly predicting the majority class (i.e., not readmitted), failing to identify actual readmission cases. For example, Ridge Classifier and Logistic Regression had recall values below 2%, and the Dummy Classifier set a high baseline accuracy simply by predicting all negatives. These results highlighted the impact of class imbalance and the need for better strategies to detect minority class cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Comparant models........ esperant........ pot tardar uns minuts...\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_4a969 th {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_4a969_row0_col0, #T_4a969_row0_col3, #T_4a969_row0_col5, #T_4a969_row0_col6, #T_4a969_row0_col7, #T_4a969_row1_col0, #T_4a969_row1_col1, #T_4a969_row1_col2, #T_4a969_row1_col3, #T_4a969_row1_col4, #T_4a969_row1_col5, #T_4a969_row2_col0, #T_4a969_row2_col1, #T_4a969_row2_col2, #T_4a969_row2_col3, #T_4a969_row2_col4, #T_4a969_row2_col5, #T_4a969_row2_col6, #T_4a969_row2_col7, #T_4a969_row3_col0, #T_4a969_row3_col1, #T_4a969_row3_col2, #T_4a969_row3_col4, #T_4a969_row3_col6, #T_4a969_row3_col7 {\n",
              "  text-align: left;\n",
              "}\n",
              "#T_4a969_row0_col1, #T_4a969_row0_col2, #T_4a969_row0_col4, #T_4a969_row1_col6, #T_4a969_row1_col7, #T_4a969_row3_col3, #T_4a969_row3_col5 {\n",
              "  text-align: left;\n",
              "  background-color: yellow;\n",
              "}\n",
              "#T_4a969_row0_col8, #T_4a969_row1_col8 {\n",
              "  text-align: left;\n",
              "  background-color: lightgrey;\n",
              "}\n",
              "#T_4a969_row2_col8, #T_4a969_row3_col8 {\n",
              "  text-align: left;\n",
              "  background-color: yellow;\n",
              "  background-color: lightgrey;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_4a969\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_4a969_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
              "      <th id=\"T_4a969_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
              "      <th id=\"T_4a969_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
              "      <th id=\"T_4a969_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
              "      <th id=\"T_4a969_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
              "      <th id=\"T_4a969_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
              "      <th id=\"T_4a969_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
              "      <th id=\"T_4a969_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
              "      <th id=\"T_4a969_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_4a969_level0_row0\" class=\"row_heading level0 row0\" >rf</th>\n",
              "      <td id=\"T_4a969_row0_col0\" class=\"data row0 col0\" >Random Forest Classifier</td>\n",
              "      <td id=\"T_4a969_row0_col1\" class=\"data row0 col1\" >0.7819</td>\n",
              "      <td id=\"T_4a969_row0_col2\" class=\"data row0 col2\" >0.6383</td>\n",
              "      <td id=\"T_4a969_row0_col3\" class=\"data row0 col3\" >0.0762</td>\n",
              "      <td id=\"T_4a969_row0_col4\" class=\"data row0 col4\" >0.6342</td>\n",
              "      <td id=\"T_4a969_row0_col5\" class=\"data row0 col5\" >0.1352</td>\n",
              "      <td id=\"T_4a969_row0_col6\" class=\"data row0 col6\" >0.0924</td>\n",
              "      <td id=\"T_4a969_row0_col7\" class=\"data row0 col7\" >0.1625</td>\n",
              "      <td id=\"T_4a969_row0_col8\" class=\"data row0 col8\" >0.0610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4a969_level0_row1\" class=\"row_heading level0 row1\" >lightgbm</th>\n",
              "      <td id=\"T_4a969_row1_col0\" class=\"data row1 col0\" >Light Gradient Boosting Machine</td>\n",
              "      <td id=\"T_4a969_row1_col1\" class=\"data row1 col1\" >0.7785</td>\n",
              "      <td id=\"T_4a969_row1_col2\" class=\"data row1 col2\" >0.6018</td>\n",
              "      <td id=\"T_4a969_row1_col3\" class=\"data row1 col3\" >0.1554</td>\n",
              "      <td id=\"T_4a969_row1_col4\" class=\"data row1 col4\" >0.5465</td>\n",
              "      <td id=\"T_4a969_row1_col5\" class=\"data row1 col5\" >0.2391</td>\n",
              "      <td id=\"T_4a969_row1_col6\" class=\"data row1 col6\" >0.1539</td>\n",
              "      <td id=\"T_4a969_row1_col7\" class=\"data row1 col7\" >0.1974</td>\n",
              "      <td id=\"T_4a969_row1_col8\" class=\"data row1 col8\" >0.4460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4a969_level0_row2\" class=\"row_heading level0 row2\" >dummy</th>\n",
              "      <td id=\"T_4a969_row2_col0\" class=\"data row2 col0\" >Dummy Classifier</td>\n",
              "      <td id=\"T_4a969_row2_col1\" class=\"data row2 col1\" >0.7744</td>\n",
              "      <td id=\"T_4a969_row2_col2\" class=\"data row2 col2\" >0.5000</td>\n",
              "      <td id=\"T_4a969_row2_col3\" class=\"data row2 col3\" >0.0000</td>\n",
              "      <td id=\"T_4a969_row2_col4\" class=\"data row2 col4\" >0.0000</td>\n",
              "      <td id=\"T_4a969_row2_col5\" class=\"data row2 col5\" >0.0000</td>\n",
              "      <td id=\"T_4a969_row2_col6\" class=\"data row2 col6\" >0.0000</td>\n",
              "      <td id=\"T_4a969_row2_col7\" class=\"data row2 col7\" >0.0000</td>\n",
              "      <td id=\"T_4a969_row2_col8\" class=\"data row2 col8\" >0.0120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4a969_level0_row3\" class=\"row_heading level0 row3\" >dt</th>\n",
              "      <td id=\"T_4a969_row3_col0\" class=\"data row3 col0\" >Decision Tree Classifier</td>\n",
              "      <td id=\"T_4a969_row3_col1\" class=\"data row3 col1\" >0.6776</td>\n",
              "      <td id=\"T_4a969_row3_col2\" class=\"data row3 col2\" >0.5529</td>\n",
              "      <td id=\"T_4a969_row3_col3\" class=\"data row3 col3\" >0.3258</td>\n",
              "      <td id=\"T_4a969_row3_col4\" class=\"data row3 col4\" >0.3023</td>\n",
              "      <td id=\"T_4a969_row3_col5\" class=\"data row3 col5\" >0.3128</td>\n",
              "      <td id=\"T_4a969_row3_col6\" class=\"data row3 col6\" >0.1031</td>\n",
              "      <td id=\"T_4a969_row3_col7\" class=\"data row3 col7\" >0.1034</td>\n",
              "      <td id=\"T_4a969_row3_col8\" class=\"data row3 col8\" >0.0120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x325e93700>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Paso 4: Comparar Modelos\n",
        "print(\"\\nComparant models........ esperant........ pot tardar uns minuts...\")\n",
        "best_model = compare_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 📈 Visualización de Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 🚀 Despliegue (Futuro)\n",
        "Se puede utilizar Hugging Face Spaces o Streamlit Cloud para desplegar un frontend que permita:\n",
        "- Cargar variables clínicas\n",
        "- Obtener un score de riesgo\n",
        "- Visualizar el gráfico ROC o una matriz de confusión"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ogi",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.22"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
