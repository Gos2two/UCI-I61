{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#  An谩lisis de la Readmisi贸n a la UCI en Pacientes con Hemorragia Intracerebral (MIMIC-IV)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.  Configuraci贸n Inicial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/marc/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello, World!\n"
          ]
        }
      ],
      "source": [
        "from google.cloud import bigquery\n",
        "from google.oauth2 import service_account\n",
        "\n",
        "# Path to your service account key file\n",
        "SERVICE_ACCOUNT_FILE = \"mimic-sergi.json\"\n",
        "PROJECT_ID = \"ogi-uci-i61\"\n",
        "\n",
        "# Create credentials and client\n",
        "credentials = service_account.Credentials.from_service_account_file(\n",
        "    SERVICE_ACCOUNT_FILE)\n",
        "\n",
        "client = bigquery.Client(credentials=credentials, project=PROJECT_ID)\n",
        "\n",
        "# Example query\n",
        "query = \"SELECT 'Hello, World!' AS greeting\"\n",
        "query_job = client.query(query)\n",
        "\n",
        "# Fetch results\n",
        "results = query_job.result()\n",
        "\n",
        "for row in results:\n",
        "    print(row.greeting)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.  Extracci贸n de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/marc/Library/Python/3.9/lib/python/site-packages/google/cloud/bigquery/table.py:1933: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "query = \"\"\"\n",
        "SELECT\n",
        "  a.subject_id,\n",
        "  a.hadm_id,\n",
        "  a.stay_id,\n",
        "  p.gender,\n",
        "  a.intime,\n",
        "  a.outtime,\n",
        "  i.icd_code,\n",
        "  d.icd_version,\n",
        "  d.long_title,\n",
        "  s.gcs_verbal,\n",
        "  s.gcs_motor,\n",
        "  s.gcs_eyes,\n",
        "  vitals.heart_rate,\n",
        "  vitals.mbp,\n",
        "  vitals.resp_rate,\n",
        "  vitals.temperature,\n",
        "  vitals.spo2,\n",
        "  readmit.stay_id AS readmitted_stay\n",
        "FROM\n",
        "  `ogi-uci-i61.mimiciv_icu.icustays` a\n",
        "JOIN\n",
        "  `ogi-uci-i61.mimiciv_hosp.patients` p\n",
        "  ON a.subject_id = p.subject_id\n",
        "JOIN\n",
        "  `ogi-uci-i61.mimiciv_hosp.diagnoses_icd` i\n",
        "  ON a.hadm_id = i.hadm_id\n",
        "JOIN\n",
        "  `ogi-uci-i61.mimiciv_hosp.d_icd_diagnoses` d\n",
        "  ON i.icd_code = d.icd_code AND i.icd_version = d.icd_version\n",
        "LEFT JOIN (\n",
        "  -- Select first GCS per stay\n",
        "  SELECT\n",
        "    stay_id,\n",
        "    gcs_verbal,\n",
        "    gcs_motor,\n",
        "    gcs_eyes,\n",
        "    ROW_NUMBER() OVER (PARTITION BY stay_id ORDER BY charttime) AS rn\n",
        "  FROM\n",
        "    `ogi-uci-i61.mimiciv_derived.gcs`\n",
        ") s\n",
        "  ON a.stay_id = s.stay_id AND s.rn = 1\n",
        "LEFT JOIN (\n",
        "  -- Select first vitals per stay\n",
        "  SELECT\n",
        "    stay_id,\n",
        "    heart_rate,\n",
        "    mbp,\n",
        "    resp_rate,\n",
        "    temperature,\n",
        "    spo2,\n",
        "    ROW_NUMBER() OVER (PARTITION BY stay_id ORDER BY charttime) AS rn\n",
        "  FROM\n",
        "    `ogi-uci-i61.mimiciv_derived.vitalsign`\n",
        ") vitals\n",
        "  ON a.stay_id = vitals.stay_id AND vitals.rn = 1\n",
        "LEFT JOIN (\n",
        "  -- Identify next stay as readmission\n",
        "  SELECT\n",
        "    a1.subject_id,\n",
        "    a1.stay_id,\n",
        "    MIN(a2.stay_id) AS readmitted_stay\n",
        "  FROM\n",
        "    `ogi-uci-i61.mimiciv_icu.icustays` a1\n",
        "  JOIN\n",
        "    `ogi-uci-i61.mimiciv_icu.icustays` a2\n",
        "    ON a1.subject_id = a2.subject_id\n",
        "    AND a2.intime > a1.outtime\n",
        "  GROUP BY\n",
        "    a1.subject_id, a1.stay_id\n",
        ") readmit\n",
        "  ON a.subject_id = readmit.subject_id AND a.stay_id = readmit.stay_id\n",
        "WHERE\n",
        "  LOWER(d.long_title) LIKE '%intracerebral hemorrhage%'\n",
        "\"\"\"\n",
        "df = client.query(query).to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Ы Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nulls in readmitted_stay before fillna: 3222\n",
            "readmitted_stay summary: count              938.0\n",
            "mean     35030430.127932\n",
            "std       2878265.870109\n",
            "min           30024491.0\n",
            "25%           32506322.0\n",
            "50%           34949251.5\n",
            "75%          37500054.75\n",
            "max           39979862.0\n",
            "Name: readmitted_stay, dtype: Float64\n",
            "Class distribution in readmitted: readmitted\n",
            "0    3222\n",
            "1     938\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Inspect readmitted_stay\n",
        "print(\"Nulls in readmitted_stay before fillna:\", df['readmitted_stay'].isnull().sum())\n",
        "print(\"readmitted_stay summary:\", df['readmitted_stay'].describe())\n",
        "\n",
        "# Create readmitted (adjust based on readmitted_stay's meaning)\n",
        "df['readmitted'] = df['readmitted_stay'].notnull().astype(int)  # Or (df['readmitted_stay'] > 0).astype(int)\n",
        "\n",
        "# Verify readmitted\n",
        "print(\"Class distribution in readmitted:\", df['readmitted'].value_counts())\n",
        "if len(df['readmitted'].unique()) < 2:\n",
        "    raise ValueError(\"readmitted has only one class. Redefine the target.\")\n",
        "\n",
        "# Identify integer columns\n",
        "int_columns = df.select_dtypes(include=['Int64', 'int64']).columns\n",
        "\n",
        "# Fill NaNs with rounded medians for integer columns\n",
        "for col in int_columns:\n",
        "    median_val = df[col].median()\n",
        "    if not pd.isna(median_val):\n",
        "        df[col] = df[col].fillna(int(median_val))\n",
        "\n",
        "# Fill NaNs for other numeric columns, excluding readmitted_stay\n",
        "numeric_cols = df.select_dtypes(include='number').columns.difference(['readmitted_stay'])\n",
        "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "\n",
        "# Handle readmitted_stay separately\n",
        "df['readmitted_stay'] = df['readmitted_stay'].fillna(0)\n",
        "\n",
        "# Scale features\n",
        "\n",
        "scaler = StandardScaler()\n",
        "# Select numeric columns, excluding readmitted_stay and readmitted\n",
        "numeric_cols = df.select_dtypes(include='number').columns.difference(['readmitted_stay', 'readmitted'])\n",
        "features_scaled = scaler.fit_transform(df[numeric_cols])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.  Modelado Predictivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.98      0.88       806\n",
            "           1       0.69      0.12      0.21       234\n",
            "\n",
            "    accuracy                           0.79      1040\n",
            "   macro avg       0.74      0.55      0.54      1040\n",
            "weighted avg       0.77      0.79      0.73      1040\n",
            "\n",
            "AUC: 0.6065168289113699\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "X = features_scaled\n",
        "y = df['readmitted']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_proba = model.predict_proba(X_test)[:,1]\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"AUC:\", roc_auc_score(y_test, y_proba))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.  Visualizaci贸n de Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel(\"FPR\")\n",
        "plt.ylabel(\"TPR\")\n",
        "plt.title(\"Curva ROC\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.  Despliegue (Futuro)\n",
        "Se puede utilizar Hugging Face Spaces o Streamlit Cloud para desplegar un frontend que permita:\n",
        "- Cargar variables cl铆nicas\n",
        "- Obtener un score de riesgo\n",
        "- Visualizar el gr谩fico ROC o una matriz de confusi贸n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
